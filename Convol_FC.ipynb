{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convol_FC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6GEgLgbxwyks",
        "YeEstXs01eAu",
        "Pq6fLNGJGmMF",
        "akNb_gfVcWLq",
        "2qrdP0PXu3mn"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPir5W2dCVnDcrlOpgoedND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wataru133/Code/blob/master/Convol_FC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GEgLgbxwyks"
      },
      "source": [
        "# Install Flat Buffer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmjBnt6rqQyT",
        "outputId": "9c05af91-03a6-45a8-9d71-d95e0f9075f7"
      },
      "source": [
        "# Install\n",
        "!pip install flatbuffers==1.12.0\n",
        "import flatbuffers\n",
        "%cd /content/\n",
        "!rm -rf flatbuffers*\n",
        "!curl -L \"https://github.com/google/flatbuffers/archive/v1.12.0.zip\" -o flatbuffers.zip\n",
        "!unzip -q flatbuffers.zip\n",
        "!mv flatbuffers-1.12.0 flatbuffers\n",
        "%cd flatbuffers\n",
        "!cmake -G \"Unix Makefiles\" -DCMAKE_BUILD_TYPE=Release\n",
        "!make -j 8\n",
        "!cp flatc /usr/local/bin/\n",
        "%cd /content/\n",
        "!rm -rf tensorflow\n",
        "%tensorflow_version 1.x\n",
        "!wget https://github.com/tensorflow/tensorflow/archive/v2.4.1.zip\n",
        "!unzip v2.4.1.zip &> 0\n",
        "!mv tensorflow-2.4.1/ tensorflow/\n",
        "!flatc --python --gen-object-api tensorflow/tensorflow/lite/schema/schema_v3.fbs\n",
        "import sys\n",
        "# This hackery allows us to import the Python files we've just generated.\n",
        "sys.path.append(\"/content/tflite/\")\n",
        "import Model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flatbuffers==1.12.0 in /usr/local/lib/python3.7/dist-packages (1.12)\n",
            "/content\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   124  100   124    0     0    765      0 --:--:-- --:--:-- --:--:--   765\n",
            "100 1463k    0 1463k    0     0  2540k      0 --:--:-- --:--:-- --:--:-- 6749k\n",
            "/content/flatbuffers\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for strtof_l\n",
            "-- Looking for strtof_l - found\n",
            "-- Looking for strtoull_l\n",
            "-- Looking for strtoull_l - found\n",
            "-- `tests/monster_test.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `tests/monster_test.fbs`: add generation of binary (.bfbs) schema\n",
            "-- `tests/namespace_test/namespace_test1.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `tests/namespace_test/namespace_test2.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `tests/union_vector/union_vector.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `tests/native_type_test.fbs`: add generation of C++ code with ''\n",
            "-- `tests/arrays_test.fbs`: add generation of C++ code with '--scoped-enums;--gen-compare'\n",
            "-- `tests/arrays_test.fbs`: add generation of binary (.bfbs) schema\n",
            "-- `tests/monster_test.fbs`: add generation of C++ embedded binary schema code with '--no-includes;--gen-compare'\n",
            "-- `tests/monster_extra.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `samples/monster.fbs`: add generation of C++ code with '--no-includes;--gen-compare'\n",
            "-- `samples/monster.fbs`: add generation of binary (.bfbs) schema\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/flatbuffers\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatbuffers\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatc\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flathash\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/flathash.dir/src/flathash.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/util.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/reflection.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object CMakeFiles/flatbuffers.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/reflection.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32m\u001b[1mLinking CXX executable flathash\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/util.cpp.o\u001b[0m\n",
            "[ 11%] Built target flathash\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_cpp.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_csharp.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_dart.cpp.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_kotlin.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_go.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_java.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_js_ts.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_php.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_python.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_lobster.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_lua.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_rust.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_fbs.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_grpc.cpp.o\u001b[0m\n",
            "[ 29%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_json_schema.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/idl_gen_swift.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/flatc.cpp.o\u001b[0m\n",
            "[ 32%] \u001b[32m\u001b[1mLinking CXX static library libflatbuffers.a\u001b[0m\n",
            "[ 32%] Built target flatbuffers\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/flatc_main.cpp.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/src/code_generators.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/cpp_generator.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/go_generator.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/java_generator.cc.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/python_generator.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/flatc.dir/grpc/src/compiler/swift_generator.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32m\u001b[1mLinking CXX executable flatc\u001b[0m\n",
            "[ 42%] Built target flatc\n",
            "\u001b[35m\u001b[1mScanning dependencies of target generated_code\u001b[0m\n",
            "[ 43%] \u001b[34m\u001b[1mRun generation: 'samples/monster.bfbs'\u001b[0m\n",
            "[ 45%] \u001b[34m\u001b[1mRun generation: 'tests/namespace_test/namespace_test1_generated.h'\u001b[0m\n",
            "[ 45%] \u001b[34m\u001b[1mRun generation: 'tests/native_type_test_generated.h'\u001b[0m\n",
            "[ 47%] \u001b[34m\u001b[1mRun generation: 'tests/union_vector/union_vector_generated.h'\u001b[0m\n",
            "[ 48%] \u001b[34m\u001b[1mRun generation: 'tests/arrays_test_generated.h'\u001b[0m\n",
            "[ 49%] \u001b[34m\u001b[1mRun generation: 'tests/arrays_test.bfbs'\u001b[0m\n",
            "[ 50%] \u001b[34m\u001b[1mRun generation: 'tests/monster_test_generated.h'\u001b[0m\n",
            "[ 51%] \u001b[34m\u001b[1mRun generation: 'tests/namespace_test/namespace_test2_generated.h'\u001b[0m\n",
            "[ 52%] \u001b[34m\u001b[1mRun generation: 'tests/monster_test.bfbs'\u001b[0m\n",
            "[ 54%] \u001b[34m\u001b[1mRun generation: 'tests/monster_test_bfbs_generated.h'\u001b[0m\n",
            "[ 55%] \u001b[34m\u001b[1mRun generation: 'tests/monster_extra_generated.h'\u001b[0m\n",
            "[ 56%] \u001b[34m\u001b[1mRun generation: 'samples/monster_generated.h'\u001b[0m\n",
            "[ 57%] \u001b[34m\u001b[1mAll generated files were updated.\u001b[0m\n",
            "[ 57%] Built target generated_code\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatsamplebfbs\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatsamplebinary\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flattests\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target flatsampletext\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebinary.dir/samples/sample_binary.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/util.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/samples/sample_bfbs.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/reflection.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/flatsamplebfbs.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/idl_parser.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32m\u001b[1mLinking CXX executable flatsamplebinary\u001b[0m\n",
            "[ 70%] Built target flatsamplebinary\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/reflection.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/src/util.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/flatsampletext.dir/samples/sample_text.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/idl_gen_text.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/reflection.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/util.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/idl_gen_fbs.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/test.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/test_assert.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/native_type_test_impl.cpp.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/tests/test_builder.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/flattests.dir/src/code_generators.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32m\u001b[1mLinking CXX executable flatsampletext\u001b[0m\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX executable flatsamplebfbs\u001b[0m\n",
            "[ 88%] Built target flatsamplebfbs\n",
            "[ 89%] Built target flatsampletext\n",
            "[ 90%] \u001b[32m\u001b[1mLinking CXX executable flattests\u001b[0m\n",
            "[100%] Built target flattests\n",
            "/content\n",
            "--2021-10-22 09:45:47--  https://github.com/tensorflow/tensorflow/archive/v2.4.1.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/tensorflow/tensorflow/zip/v2.4.1 [following]\n",
            "--2021-10-22 09:45:47--  https://codeload.github.com/tensorflow/tensorflow/zip/v2.4.1\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘v2.4.1.zip.2’\n",
            "\n",
            "v2.4.1.zip.2            [ <=>                ]  66.13M  9.23MB/s    in 7.1s    \n",
            "\n",
            "2021-10-22 09:45:55 (9.29 MB/s) - ‘v2.4.1.zip.2’ saved [69346072]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeEstXs01eAu"
      },
      "source": [
        "# Install Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWdo5wZC1kPZ",
        "outputId": "efa982c6-6d9c-4513-f3b8-4d53f83f1529"
      },
      "source": [
        "!pip install tensorflow==2.4.0"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.4.0 in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.7.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.12.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YSBtif31l7Y"
      },
      "source": [
        "# Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT4idyQ_11AG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Set seed for experiment reproducibility\n",
        "seed = 133\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Define paths to model files\n",
        "MODELS_DIR = 'models/'\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + 'model'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGNPaBuT2B06"
      },
      "source": [
        "# CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq6fLNGJGmMF"
      },
      "source": [
        "## Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_COBqsbHEue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95436bf0-a162-4e60-efb7-f296539be5d0"
      },
      "source": [
        "# Input shape\n",
        "input_shape = [1, 5, 5, 1]\n",
        "x = np.random.randint(1,10, size=input_shape).astype(np.float32) # Change type to float 32 for input of representative_dataset for convert to TFLite \n",
        "print(x)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[2.]\n",
            "   [9.]\n",
            "   [9.]\n",
            "   [2.]\n",
            "   [7.]]\n",
            "\n",
            "  [[5.]\n",
            "   [6.]\n",
            "   [3.]\n",
            "   [7.]\n",
            "   [6.]]\n",
            "\n",
            "  [[7.]\n",
            "   [7.]\n",
            "   [9.]\n",
            "   [9.]\n",
            "   [5.]]\n",
            "\n",
            "  [[8.]\n",
            "   [4.]\n",
            "   [2.]\n",
            "   [7.]\n",
            "   [4.]]\n",
            "\n",
            "  [[6.]\n",
            "   [7.]\n",
            "   [9.]\n",
            "   [3.]\n",
            "   [9.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwCksvY6Hu33"
      },
      "source": [
        "## Model CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN52mJ9W29Aw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f9c3b5-f0f2-48f6-8ab6-9a5004f3dc54"
      },
      "source": [
        "# Model with 1 CNN layer kenerl size = 3x3\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(1, (3, 3), input_shape=input_shape[1:], use_bias=True))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(2))\n",
        "\n",
        "print(model.get_weights())\n",
        "\n",
        "weight  = []\n",
        "weight1 = np.random.randint(1,10, size=(3,3,1,1)) # Weight of Convol layer\n",
        "weight2 = np.random.randint(1,10, size=(1)) # Bias of Convol layer\n",
        "weight3 = np.random.randint(1,10, size=(9,2)) # Weight of Dense layer\n",
        "weight4 = np.random.randint(1,10, size=(2,)) # Bias of Convol layer\n",
        "weight.append(weight1)\n",
        "weight.append(weight2)\n",
        "weight.append(weight3)\n",
        "weight.append(weight4)\n",
        "\n",
        "model.set_weights(weight)\n",
        "print(model.get_weights())\n",
        "\n",
        "# Save model\n",
        "model.save(MODEL_TF)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[[[ 0.01538676]],\n",
            "\n",
            "        [[-0.5477104 ]],\n",
            "\n",
            "        [[-0.34695753]]],\n",
            "\n",
            "\n",
            "       [[[-0.45251068]],\n",
            "\n",
            "        [[-0.03081071]],\n",
            "\n",
            "        [[ 0.09090585]]],\n",
            "\n",
            "\n",
            "       [[[-0.4984012 ]],\n",
            "\n",
            "        [[-0.39746004]],\n",
            "\n",
            "        [[-0.33767614]]]], dtype=float32), array([0.], dtype=float32), array([[ 0.18935436, -0.2766963 ],\n",
            "       [ 0.45313174,  0.6625735 ],\n",
            "       [ 0.05022651, -0.09159493],\n",
            "       [ 0.03842396, -0.21747208],\n",
            "       [ 0.05905038, -0.5173921 ],\n",
            "       [ 0.5508906 , -0.40164167],\n",
            "       [-0.3833571 ,  0.729672  ],\n",
            "       [ 0.7179212 , -0.5358964 ],\n",
            "       [ 0.36740094,  0.11368233]], dtype=float32), array([0., 0.], dtype=float32)]\n",
            "[array([[[[7.]],\n",
            "\n",
            "        [[3.]],\n",
            "\n",
            "        [[3.]]],\n",
            "\n",
            "\n",
            "       [[[3.]],\n",
            "\n",
            "        [[9.]],\n",
            "\n",
            "        [[3.]]],\n",
            "\n",
            "\n",
            "       [[[8.]],\n",
            "\n",
            "        [[3.]],\n",
            "\n",
            "        [[9.]]]], dtype=float32), array([6.], dtype=float32), array([[3., 8.],\n",
            "       [8., 3.],\n",
            "       [8., 1.],\n",
            "       [3., 1.],\n",
            "       [5., 9.],\n",
            "       [4., 2.],\n",
            "       [4., 3.],\n",
            "       [2., 5.],\n",
            "       [7., 4.]], dtype=float32), array([8., 9.], dtype=float32)]\n",
            "INFO:tensorflow:Assets written to: models/model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm1EgSf2_LSH"
      },
      "source": [
        "### TFLite no quantization model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6qMHhFI_mzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec7dad9-b245-4c0f-ef26-819dceb7ec69"
      },
      "source": [
        "# Convert the TF model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
        "model_no_quant_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1656"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEzaIXwUEnaT"
      },
      "source": [
        "### TFLite quantization model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEmLO6YSE--f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc4ef8d-b11a-45e8-b97c-cb957dc568b0"
      },
      "source": [
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "def representative_dataset():\n",
        "    # yield([x.reshape(input_shape)])\n",
        "    yield([x])\n",
        "\n",
        "# Enforce integer only quantization\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "converter.representative_dataset = representative_dataset\n",
        "\n",
        "# Convert the TF model to the TensorFlow Lite format with quantization\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2056"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lir1TWb_khq-"
      },
      "source": [
        "## Prediction with 3 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgvUn4t8nvdL"
      },
      "source": [
        "# predict functions for TFLite models\n",
        "def predict_tflite(tflite_model, x_test):\n",
        "  # Prepare the test data\n",
        "  x_test_ = x_test\n",
        "\n",
        "  # Initialize the TFLite interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  # print(input_details)\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "  # print(output_details)\n",
        "\n",
        "  # If required, quantize the input layer (from float to integer)\n",
        "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "  if (input_scale, input_zero_point) != (0.0, 0):\n",
        "    x_test_ = x_test_ / input_scale + input_zero_point\n",
        "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
        "  \n",
        "  # Invoke the interpreter\n",
        "  y_pred = np.empty(output_details[\"shape\"], dtype=output_details[\"dtype\"])\n",
        "  interpreter.set_tensor(input_details[\"index\"], x_test_)\n",
        "  interpreter.invoke()\n",
        "  y_pred = interpreter.get_tensor(output_details[\"index\"])\n",
        "  # print(interpreter.get_tensor(output_details[\"index\"]))\n",
        "  \n",
        "  # If required, dequantized the output layer (from integer to float)\n",
        "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "  if (output_scale, output_zero_point) != (0.0, 0):\n",
        "    y_pred = y_pred.astype(np.float32)\n",
        "    y_pred = (y_pred - output_zero_point) * output_scale\n",
        "\n",
        "  return y_pred"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmzNJDPgkrjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029b1ba5-dfbb-4005-ce51-7a506c585a74"
      },
      "source": [
        "# Output of TF\n",
        "y = model.predict(x)\n",
        "print(y)\n",
        "\n",
        "# Output of TFL no quantization\n",
        "y = predict_tflite(model_no_quant_tflite, x)\n",
        "print(y)\n",
        "\n",
        "# Output of TFL quantization\n",
        "y = predict_tflite(model_tflite, x)\n",
        "print(y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[13935. 11107.]]\n",
            "[[13935. 11107.]]\n",
            "[[13880.354 11038.706]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akNb_gfVcWLq"
      },
      "source": [
        "# Vela Compiler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD0ATqwqcdl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414bf91f-263d-4b3e-8555-bfb07677d967"
      },
      "source": [
        "# Install\n",
        "!pip install ethos-u-vela"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ethos-u-vela\n",
            "  Downloading ethos-u-vela-3.1.0.tar.gz (304 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 304 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers==1.12.0 in /usr/local/lib/python3.7/dist-packages (from ethos-u-vela) (1.12)\n",
            "Requirement already satisfied: numpy<=1.19.5,>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from ethos-u-vela) (1.19.5)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.6.3-cp37-cp37m-manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 40.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ethos-u-vela\n",
            "  Building wheel for ethos-u-vela (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ethos-u-vela: filename=ethos_u_vela-3.1.0-cp37-cp37m-linux_x86_64.whl size=408673 sha256=c0a927510d5fa086203cc11a51ea91ea2ff24bc985f7affbe5ee1ca04f3fd8e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/3e/8a/dbbca737198be7d344a05c405e602c86b1d137037fa5774e39\n",
            "Successfully built ethos-u-vela\n",
            "Installing collected packages: lxml, ethos-u-vela\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed ethos-u-vela-3.1.0 lxml-4.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRp8t52Rcnay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f56d5c-d306-4578-cb1c-ebff8a28ece7"
      },
      "source": [
        "# Compile with no quantization model\n",
        "!vela models/model_no_quant.tflite\n",
        "!vela models/model.tflite"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Using internal-default values for system configuration\n",
            "Warning: Using internal-default values for memory mode\n",
            "Warning: unsupported TensorFlow Lite semantics for CONV_2D ';;conv2d_8/bias1'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: serving_default_conv2d_8_input:0, std.constant2_reshape, ;;conv2d_8/bias1\n",
            "Warning: unsupported TensorFlow Lite semantics for RESHAPE 'tfl.reshape'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: ;;conv2d_8/bias1, tfl.reshape\n",
            "Warning: unsupported TensorFlow Lite semantics for FULLY_CONNECTED 'StatefulPartitionedCall:0'. Placing on CPU instead\n",
            " - Input(s), Output and Weight tensors must have quantization parameters\n",
            "   Op has tensors with missing quantization parameters: tfl.reshape, std.constant1_reshape, StatefulPartitionedCall:0\n",
            "Warning: FullyConnected operation is unknown or unsupported, placing on CPU\n",
            "Warning: Conv2DBias operation is unknown or unsupported, placing on CPU\n",
            "\n",
            "Network summary for model_no_quant\n",
            "Accelerator configuration               Ethos_U55_256\n",
            "System configuration                 internal-default\n",
            "Memory mode                          internal-default\n",
            "Accelerator clock                                 500 MHz\n",
            "\n",
            "\n",
            "4 passes fused into 4\n",
            "2/9 (22.2%) operations falling back to the CPU\n",
            "Neural network macs                                 0 MACs/batch\n",
            "Network Tops/s                                    nan Tops/s\n",
            "\n",
            "NPU cycles                                          0 cycles/batch\n",
            "SRAM Access cycles                                  0 cycles/batch\n",
            "DRAM Access cycles                                  0 cycles/batch\n",
            "On-chip Flash Access cycles                         0 cycles/batch\n",
            "Off-chip Flash Access cycles                        0 cycles/batch\n",
            "Total cycles                                        0 cycles/batch\n",
            "\n",
            "Batch Inference time                 0.00 ms,     nan inferences/s (batch size 1)\n",
            "\n",
            "Warning: Using internal-default values for system configuration\n",
            "Warning: Using internal-default values for memory mode\n",
            "\n",
            "Network summary for model\n",
            "Accelerator configuration               Ethos_U55_256\n",
            "System configuration                 internal-default\n",
            "Memory mode                          internal-default\n",
            "Accelerator clock                                 500 MHz\n",
            "Design peak SRAM bandwidth                       4.00 GB/s\n",
            "Design peak Off-chip Flash bandwidth             0.50 GB/s\n",
            "\n",
            "Total SRAM used                                  0.09 KiB\n",
            "Total Off-chip Flash used                        0.69 KiB\n",
            "\n",
            "5 passes fused into 2\n",
            "0/11 (0.0%) operations falling back to the CPU\n",
            "Average SRAM bandwidth                           0.21 GB/s\n",
            "Input   SRAM bandwidth                           0.00 MB/batch\n",
            "Weight  SRAM bandwidth                           0.00 MB/batch\n",
            "Output  SRAM bandwidth                           0.00 MB/batch\n",
            "Total   SRAM bandwidth                           0.00 MB/batch\n",
            "Total   SRAM bandwidth            per input      0.00 MB/inference (batch size 1)\n",
            "\n",
            "Average Off-chip Flash bandwidth                 0.19 GB/s\n",
            "Input   Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Weight  Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Output  Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Total   Off-chip Flash bandwidth                 0.00 MB/batch\n",
            "Total   Off-chip Flash bandwidth  per input      0.00 MB/inference (batch size 1)\n",
            "\n",
            "Neural network macs                                99 MACs/batch\n",
            "Network Tops/s                                   0.00 Tops/s\n",
            "\n",
            "NPU cycles                                        312 cycles/batch\n",
            "SRAM Access cycles                                 20 cycles/batch\n",
            "DRAM Access cycles                                  0 cycles/batch\n",
            "On-chip Flash Access cycles                         0 cycles/batch\n",
            "Off-chip Flash Access cycles                       80 cycles/batch\n",
            "Total cycles                                      332 cycles/batch\n",
            "\n",
            "Batch Inference time                 0.00 ms, 1506024.10 inferences/s (batch size 1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhlZ21xiBoeT"
      },
      "source": [
        "# Flat Buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qrdP0PXu3mn"
      },
      "source": [
        "## Load CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B_zHx1Nv0MP"
      },
      "source": [
        "# Function for read/write flat buffer\n",
        "def load_model_from_file(model_filename):\n",
        "  with open(model_filename, \"rb\") as file:\n",
        "    buffer_data = file.read()\n",
        "  model_obj = Model.Model.GetRootAsModel(buffer_data, 0)\n",
        "  model = Model.ModelT.InitFromObj(model_obj)\n",
        "  return model\n",
        "\n",
        "def save_model_to_file(model, model_filename):\n",
        "  builder = flatbuffers.Builder(1024)\n",
        "  model_offset = model.Pack(builder)\n",
        "  builder.Finish(model_offset, file_identifier=b'TFL3')\n",
        "  model_data = builder.Output()\n",
        "  with open(model_filename, 'wb') as out_file:\n",
        "    out_file.write(model_data)\n",
        "    \n",
        "# Load CNNO model no quantization\n",
        "model = load_model_from_file(MODEL_NO_QUANT_TFLITE)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ka-NWA_x-CW"
      },
      "source": [
        "## Model information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iESWvFAq2BOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9caada93-f508-4abe-993c-02fb588686ac"
      },
      "source": [
        "print(model.version)\n",
        "\n",
        "print(model.description)\n",
        "\n",
        "i = 0\n",
        "for buffer in model.buffers:\n",
        "  print(f\"\\nbuffer[{i}] = {buffer.data}\")\n",
        "  if buffer.data is not None: # np.frombuffer dont accepted NoneType\n",
        "    original_weights = np.frombuffer(buffer.data, dtype=np.float32)\n",
        "    print(f\"weights = {original_weights}\\n\")\n",
        "  i+=1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "b'MLIR Converted.'\n",
            "\n",
            "buffer[0] = None\n",
            "\n",
            "buffer[1] = None\n",
            "\n",
            "buffer[2] = [ 0  0  0 65  0  0 16 65]\n",
            "weights = [8. 9.]\n",
            "\n",
            "\n",
            "buffer[3] = [255 255 255 255   9   0   0   0]\n",
            "weights = [    nan 1.3e-44]\n",
            "\n",
            "\n",
            "buffer[4] = [  0   0  64  64   0   0   0  65   0   0   0  65   0   0  64  64   0   0\n",
            " 160  64   0   0 128  64   0   0 128  64   0   0   0  64   0   0 224  64\n",
            "   0   0   0  65   0   0  64  64   0   0 128  63   0   0 128  63   0   0\n",
            "  16  65   0   0   0  64   0   0  64  64   0   0 160  64   0   0 128  64]\n",
            "weights = [3. 8. 8. 3. 5. 4. 4. 2. 7. 8. 3. 1. 1. 9. 2. 3. 5. 4.]\n",
            "\n",
            "\n",
            "buffer[5] = [  0   0 224  64   0   0  64  64   0   0  64  64   0   0  64  64   0   0\n",
            "  16  65   0   0  64  64   0   0   0  65   0   0  64  64   0   0  16  65]\n",
            "weights = [7. 3. 3. 3. 9. 3. 8. 3. 9.]\n",
            "\n",
            "\n",
            "buffer[6] = [  0   0 192  64]\n",
            "weights = [6.]\n",
            "\n",
            "\n",
            "buffer[7] = None\n",
            "\n",
            "buffer[8] = None\n",
            "\n",
            "buffer[9] = None\n",
            "\n",
            "buffer[10] = [49 46 53 46 48  0  0  0  0  0  0  0  0  0  0  0]\n",
            "weights = [4.119566e-11 6.726233e-44 0.000000e+00 0.000000e+00]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19gUpMOq6HIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a555e2-fd2c-4214-8e08-d857fc10256a"
      },
      "source": [
        "# Model has 1 subgraph\n",
        "print(model.subgraphs[0].name) # Name \"Main\"\n",
        "print(model.subgraphs[0].inputs) # Input has index 0\n",
        "print(model.subgraphs[0].outputs) # Output has index 3"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'main'\n",
            "[0]\n",
            "[8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPhG_ei6tur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d5265c-a302-4daa-9f22-298928c11e3b"
      },
      "source": [
        "## Subgraph 0 has 1 operator\n",
        "print(model.subgraphs[0].operators[0].opcodeIndex) # Operation information store in index 0 of model.operatorCodes\n",
        "print(model.operatorCodes[0].builtinCode) # Convol 2D\n",
        "print(model.operatorCodes[0].customCode) # No custom code\n",
        "\n",
        "print(model.subgraphs[0].operators[0].inputs)\n",
        "\n",
        "print(model.subgraphs[0].operators[0].outputs)\n",
        "\n",
        "print(model.subgraphs[0].operators[0].builtinOptions) # Conv2DOptions\n",
        "print(model.subgraphs[0].operators[0].builtinOptions.padding) # VALID\n",
        "print(model.subgraphs[0].operators[0].builtinOptions.strideW) # 1\n",
        "print(model.subgraphs[0].operators[0].builtinOptions.strideH) # 1\n",
        "print(model.subgraphs[0].operators[0].builtinOptions.fusedActivationFunction) # NONE\n",
        "\n",
        "print(model.subgraphs[0].operators[0].customOptions) # No custom option "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "3\n",
            "None\n",
            "[0 4 5]\n",
            "[6]\n",
            "<tflite.Conv2DOptions.Conv2DOptionsT object at 0x7ffb1b707f90>\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doFLK8LKvSDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15738ba4-fe0a-4838-cae5-fa9a06ffcb35"
      },
      "source": [
        "for index, tensor in enumerate(model.subgraphs[0].tensors):\n",
        "  print(f\"tensor[{index}].name         = {tensor.name}\") \n",
        "  print(f\"tensor[{index}].shape        = {tensor.shape}\")\n",
        "  print(f\"tensor[{index}].type         = {tensor.type}\") # 0: FLOAT3\n",
        "  print(f\"tensor[{index}].buffer_index = {tensor.buffer}\") \n",
        "  print(f\"tensor[{index}].quantization[min, max, scale, zeroPoint] = [{tensor.quantization.min}, {tensor.quantization.max}, {tensor.quantization.scale}, {tensor.quantization.zeroPoint}]\\n\\n\") "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor[0].name         = b'serving_default_conv2d_8_input:0'\n",
            "tensor[0].shape        = [1 5 5 1]\n",
            "tensor[0].type         = 0\n",
            "tensor[0].buffer_index = 1\n",
            "tensor[0].quantization[min, max, scale, zeroPoint] = [None, None, None, None]\n",
            "\n",
            "\n",
            "tensor[1].name         = b'dense_7/bias'\n",
            "tensor[1].shape        = [2]\n",
            "tensor[1].type         = 0\n",
            "tensor[1].buffer_index = 2\n",
            "tensor[1].quantization[min, max, scale, zeroPoint] = [None, None, None, None]\n",
            "\n",
            "\n",
            "tensor[2].name         = b'std.constant'\n",
            "tensor[2].shape        = [2]\n",
            "tensor[2].type         = 2\n",
            "tensor[2].buffer_index = 3\n",
            "tensor[2].quantization[min, max, scale, zeroPoint] = [None, None, None, None]\n",
            "\n",
            "\n",
            "tensor[3].name         = b'std.constant1'\n",
            "tensor[3].shape        = [2 9]\n",
            "tensor[3].type         = 0\n",
            "tensor[3].buffer_index = 4\n",
            "tensor[3].quantization[min, max, scale, zeroPoint] = [None, None, None, None]\n",
            "\n",
            "\n",
            "tensor[4].name         = b'std.constant2'\n",
            "tensor[4].shape        = [1 3 3 1]\n",
            "tensor[4].type         = 0\n",
            "tensor[4].buffer_index = 5\n",
            "tensor[4].quantization[min, max, scale, zeroPoint] = [None, None, None, None]\n",
            "\n",
            "\n",
            "tensor[5].name         = b';;conv2d_8/bias'\n",
            "tensor[5].shape        = [1]\n",
            "tensor[5].type         = 0\n",
            "tensor[5].buffer_index = 6\n",
            "tensor[5].quantization[min, max, scale, zeroPoint] = [None, None, None, None]\n",
            "\n",
            "\n",
            "tensor[6].name         = b';;conv2d_8/bias1'\n",
            "tensor[6].shape        = [1 3 3 1]\n",
            "tensor[6].type         = 0\n",
            "tensor[6].buffer_index = 7\n",
            "tensor[6].quantization[min, max, scale, zeroPoint] = [None, None, None, None]\n",
            "\n",
            "\n",
            "tensor[7].name         = b'tfl.reshape'\n",
            "tensor[7].shape        = [1 9]\n",
            "tensor[7].type         = 0\n",
            "tensor[7].buffer_index = 8\n",
            "tensor[7].quantization[min, max, scale, zeroPoint] = [None, None, None, None]\n",
            "\n",
            "\n",
            "tensor[8].name         = b'StatefulPartitionedCall:0'\n",
            "tensor[8].shape        = [1 2]\n",
            "tensor[8].type         = 0\n",
            "tensor[8].buffer_index = 9\n",
            "tensor[8].quantization[min, max, scale, zeroPoint] = [None, None, None, None]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}